{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f091c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import environment.job_search_environment as job_search_env\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from supersuit import pad_observations_v0, pad_action_space_v0\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45796123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is working on the Zoo, but not on my local machine (M1 compatibility issues)\n",
    "from ray.rllib.algorithms.ppo import PPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83500be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20e8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7a3a74d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.models.modelv2 import restore_original_dimensions\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.tune.registry import register_env\n",
    "import torch\n",
    "from torch import nn\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.torch_utils import FLOAT_MIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99df7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1, tf, tfv = try_import_tf()\n",
    "torch, _ = try_import_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "624fb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "162f4fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1213 14:18:09.422084569 2034477 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E1213 14:18:10.449733570 2034477 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E1213 14:18:10.474604494 2034477 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E1213 14:18:12.310954422 2034477 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "E1213 14:18:12.332361742 2034477 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "2022-12-13 14:18:12,453\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.8</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.8', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '128.36.232.24', 'raylet_ip_address': '128.36.232.24', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-12-13_14-18-09_420530_2034477/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-12-13_14-18-09_420530_2034477/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-12-13_14-18-09_420530_2034477', 'metrics_export_port': 54940, 'gcs_address': '128.36.232.24:58295', 'address': '128.36.232.24:58295', 'dashboard_agent_listen_port': 52365, 'node_id': '6610fad86ced0949f3cb58a0cf8ea10e43434a1ef9fe0f6154961431'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf70d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In order to deal with the Dictionary space, need to pass a custom model to RLlib.\n",
    "See: https://medium.com/@nima.siboni/rllib-with-dictionary-state-baa06b64470f\n",
    "\"\"\"\n",
    "class CandidateModelV0(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, act_space, num_outputs, model_config, name, **kwargs):\n",
    "        TorchModelV2.__init__(self, obs_space, act_space, num_outputs, model_config, name, **kwargs)\n",
    "        nn.Module.__init__(self)\n",
    "        self.internal_model = TorchFC(\n",
    "            orig_space[\"observation\"],\n",
    "            action_space,\n",
    "            num_outputs,\n",
    "            model_config,\n",
    "            name + \"_internal\",\n",
    "        )\n",
    "        self.next_layers = nn.Sequential(\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # disable action masking --> will likely lead to invalid actions\n",
    "        self.no_masking = False\n",
    "        if \"no_masking\" in model_config[\"custom_model_config\"]:\n",
    "            self.no_masking = model_config[\"custom_model_config\"][\"no_masking\"]\n",
    "        \n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Extract the available actions tensor from the observation.\n",
    "        action_mask = input_dict[\"obs\"][\"action_mask\"]\n",
    "\n",
    "        # Compute the unmasked logits.\n",
    "        logits, _ = self.internal_model({\"obs\": input_dict[\"obs\"][\"observation\"]})\n",
    "\n",
    "        # If action masking is disabled, directly return unmasked logits\n",
    "        if self.no_masking:\n",
    "            return logits, state\n",
    "\n",
    "        # Convert action_mask into a [0.0 || -inf]-type mask.\n",
    "        inf_mask = torch.clamp(torch.log(action_mask), min=FLOAT_MIN)\n",
    "        masked_logits = logits + inf_mask\n",
    "\n",
    "        # Return masked logits.\n",
    "        return masked_logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self.internal_model.value_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a25eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(args):\n",
    "    env = job_search_env.env()\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65e48f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"job_search_env\"\n",
    "register_env(env_name, lambda config: ParallelPettingZooEnv(env_creator(config)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c52ca8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"CandidateModelV0\", CandidateModelV0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b40f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use policy_map to map different policies to candidate and employer agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b2d7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=env_name, clip_actions=True)\n",
    "    .debugging(log_level=\"INFO\")\n",
    "    .framework(framework=\"torch\")\n",
    "    .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40ea3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('action_mask',\n",
       "              array([0.5912034 , 0.31818643, 0.7072217 , 0.4555924 , 0.9130571 ,\n",
       "                     0.4395524 , 0.7184257 , 0.8531792 , 0.3151884 , 0.0221843 ,\n",
       "                     0.54910654, 0.8929718 , 0.20084727, 0.32389998, 0.36311245,\n",
       "                     0.5390295 , 0.32319862, 0.58507556, 0.5480227 , 0.9190869 ,\n",
       "                     0.6003524 , 0.45522314, 0.9095524 , 0.8173227 , 0.8408659 ,\n",
       "                     0.90662867, 0.72106504, 0.20718214, 0.5140049 , 0.6678512 ,\n",
       "                     0.882626  , 0.9587595 , 0.5306524 , 0.39655983, 0.76883566,\n",
       "                     0.31444845, 0.40452632, 0.8572186 , 0.00417172, 0.03190569,\n",
       "                     0.13923648, 0.04074659, 0.3246549 , 0.47971487, 0.1293372 ,\n",
       "                     0.30926323, 0.2431683 , 0.1791058 , 0.38343623, 0.39568964,\n",
       "                     0.03931836, 0.27943838, 0.29666746, 0.8323011 , 0.5389206 ,\n",
       "                     0.37395474, 0.4580046 , 0.2286979 , 0.4982664 , 0.22172345,\n",
       "                     0.7763211 , 0.9516644 , 0.09948961, 0.3837037 , 0.2970836 ,\n",
       "                     0.4303143 , 0.64611995, 0.98827606, 0.02029309, 0.08497611,\n",
       "                     0.7851196 , 0.40089688, 0.9577384 , 0.49979472, 0.6230277 ,\n",
       "                     0.7633698 , 0.59552395, 0.5271814 , 0.34804952, 0.7052139 ,\n",
       "                     0.4813347 , 0.9493528 , 0.77078265, 0.20513193, 0.01688932,\n",
       "                     0.09082634, 0.5583693 , 0.5901181 , 0.7868307 , 0.38282055,\n",
       "                     0.66746134, 0.6119436 , 0.1291681 , 0.5786458 , 0.16620055,\n",
       "                     0.36944488, 0.5322367 , 0.7782129 , 0.4340102 , 0.70082146,\n",
       "                     0.81970334, 0.8930739 , 0.39764708, 0.49443707, 0.09334536,\n",
       "                     0.23766893, 0.8977275 , 0.4596862 , 0.6860347 , 0.00945444,\n",
       "                     0.6328852 , 0.41824055, 0.92074746, 0.9133075 , 0.49333787,\n",
       "                     0.85597485, 0.35564476, 0.25421524], dtype=float32)),\n",
       "             ('observation',\n",
       "              OrderedDict([('candidate_obs',\n",
       "                            OrderedDict([('accepted_offer',\n",
       "                                          OrderedDict([('employer_0', 81)])),\n",
       "                                         ('counter_offers',\n",
       "                                          OrderedDict([('employer_0',\n",
       "                                                        (41, 5))])),\n",
       "                                         ('current_offers',\n",
       "                                          OrderedDict([('employer_0',\n",
       "                                                        (63, 1))])),\n",
       "                                         ('job_openings',\n",
       "                                          OrderedDict([('employer_0', 1)])),\n",
       "                                         ('rejected_offers',\n",
       "                                          OrderedDict([('employer_0',\n",
       "                                                        (0, 79))]))])),\n",
       "                           ('employer_obs',\n",
       "                            OrderedDict([('accepted_offers',\n",
       "                                          OrderedDict([('candidate_0', 1)])),\n",
       "                                         ('candidate_strengths',\n",
       "                                          OrderedDict([('candidate_0', 6)])),\n",
       "                                         ('counter_offers',\n",
       "                                          OrderedDict([('candidate_0',\n",
       "                                                        (42, 3))])),\n",
       "                                         ('declined_offers',\n",
       "                                          OrderedDict([('candidate_0',\n",
       "                                                        (0, 69))])),\n",
       "                                         ('job_applicants',\n",
       "                                          OrderedDict([('candidate_0', 1)])),\n",
       "                                         ('outstanding_offers',\n",
       "                                          OrderedDict([('candidate_0',\n",
       "                                                        (27, 9))])),\n",
       "                                         ('rejected_offers',\n",
       "                                          OrderedDict([('candidate_0',\n",
       "                                                        (0, 35))])),\n",
       "                                         ('remaining_budget', 49)]))]))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_search_env.env().observation_space(\"candidate_0\").sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93b778a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(action_mask:Box(0.0, 1.0, (118,), float32), observation:Dict(candidate_obs:Dict(accepted_offer:Dict(employer_0:Discrete(101)), counter_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11))), current_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11))), job_openings:Dict(employer_0:Discrete(2)), rejected_offers:Dict(employer_0:Tuple(Discrete(2), Discrete(101)))), employer_obs:Dict(accepted_offers:Dict(candidate_0:Discrete(2)), candidate_strengths:Dict(candidate_0:Discrete(101)), counter_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11))), declined_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101))), job_applicants:Dict(candidate_0:Discrete(2)), outstanding_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11))), rejected_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101))), remaining_budget:Discrete(101))))\n"
     ]
    }
   ],
   "source": [
    "config[\"observation_space\"] = job_search_env.env().observation_space(\"candidate_0\")\n",
    "config[\"action_space\"] = job_search_env.env().action_space(\"candidate_0\")\n",
    "# There's something wrong with my observation space, not able to be flattened by the Dict FlatteningPreprocessor\n",
    "# config[\"observation_space\"] = Dict({\"test1\": Discrete(10)})\n",
    "# config[\"action_space\"] = Tuple((Discrete(3), Discrete(10)))\n",
    "print (config[\"observation_space\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8afa733c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-13 14:18:31</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:17.25        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.7/62.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/28.54 GiB heap, 0.0/14.27 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_job_search_env_e3dec_00000</td><td style=\"text-align: right;\">           1</td><td>/home/accts/ahc49/ray_results/job_search_env/PPO/PPO_job_search_env_e3dec_00000_0_2022-12-13_14-18-14/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>status  </th><th>loc                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_job_search_env_e3dec_00000</td><td>ERROR   </td><td>128.36.232.24:2045783</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2045783)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m 2022-12-13 14:18:23,160\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m 2022-12-13 14:18:23,161\tINFO algorithm.py:457 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=2045906)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2045905)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.825502227 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m /home/accts/ahc49/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m   warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.847285833 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.863308126 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.799714231 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m /home/accts/ahc49/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m   warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.822558959 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.839777186 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.856099466 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.872131557 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.879340423 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.895476316 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.911170341 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.926731335 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.942498737 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045906)\u001b[0m E1213 14:18:30.959033947 2045906 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.888441695 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.904318967 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.920255256 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2045905)\u001b[0m E1213 14:18:30.936096852 2045905 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.046464090 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m /home/accts/ahc49/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m   warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.067688993 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.084018381 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.099848742 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.115049414 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.130232322 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.145176934 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.160174393 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m E1213 14:18:31.175310056 2045783 fork_posix.cc:70]           Fork support is only compatible with the epoll1 and poll polling strategies\n",
      "\u001b[2m\u001b[36m(PPO pid=2045783)\u001b[0m 2022-12-13 14:18:31,266\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "2022-12-13 14:18:31,296\tERROR trial_runner.py:993 -- Trial PPO_job_search_env_e3dec_00000: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::PPO.train()\u001b[39m (pid=2045783, ip=128.36.232.24, repr=PPO)\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
      "    result = self.step()\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
      "    num_recreated += self.try_recover_from_step_attempt(\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
      "    raise error\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
      "    train_batch = synchronous_parallel_sample(\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
      "    sample_batches = ray.get(\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::RolloutWorker.sample()\u001b[39m (pid=2045906, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f68b792dde0>)\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 615, in send_actions\n",
      "    raise e\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 608, in send_actions\n",
      "    obs, rewards, dones, infos = env.step(agent_dict)\n",
      "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py\", line 184, in step\n",
      "    obss, rews, dones, infos = self.par_env.step(action_dict)\n",
      "  File \"/home/accts/ahc49/csec491/salary-negotation/environment/job_search_environment.py\", line 394, in step\n",
      "    action, target_index, new_offer_value, new_deadline = actions[agent]\n",
      "KeyError: 'employer_0'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>date               </th><th>experiment_id                   </th><th>hostname         </th><th>node_ip      </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_job_search_env_e3dec_00000</td><td>2022-12-13_14-18-31</td><td>e45750a839f0470c82621d84a1bbe060</td><td>swan.zoo.yale.edu</td><td>128.36.232.24</td><td style=\"text-align: right;\">2045783</td><td style=\"text-align: right;\"> 1670959111</td><td>e3dec_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_job_search_env_e3dec_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     stop\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimesteps_total\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000000\u001b[39m},\n\u001b[1;32m      5\u001b[0m     checkpoint_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      6\u001b[0m     local_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/ray_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env_name,\n\u001b[1;32m      7\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/tune/tune.py:771\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 771\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_job_search_env_e3dec_00000])"
     ]
    }
   ],
   "source": [
    "tune.run(\n",
    "    \"PPO\",\n",
    "    name=\"PPO\",\n",
    "    stop={\"timesteps_total\": 5000000},\n",
    "    checkpoint_freq=10,\n",
    "    local_dir=\"~/ray_results/\" + env_name,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8cfa6",
   "metadata": {},
   "source": [
    "### Use gym.space instead of gymnasium.spaces to fix this AHHHHH\n",
    "```\n",
    "from gym.spaces import Discrete, Dict, Tuple\n",
    "\n",
    "from gym.spaces.utils import flatten, flatdim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6119029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gym.spaces import Discrete, Dict, Tuple, Box\n",
    "\n",
    "from gym.spaces.utils import flatten, flatdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03395401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(flatdim(Tuple((Discrete(4), Discrete(2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc19a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0677654 , 0.23583731, 0.8888724 , 0.33140177, 0.83999246,\n",
       "       0.9411625 , 0.95278305, 0.8704072 , 0.7740929 , 0.21301661],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0.0, 1.0, shape=(10,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5640cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01597711, 0.0812292 , 0.5303037 , 0.08253974, 0.21143797,\n",
       "       0.8212157 , 0.40818214, 0.7235936 , 0.9917055 , 0.15072973],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0.0, 1, shape=(10,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335253fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695ffb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c4d728",
   "metadata": {},
   "source": [
    "# Run 1\n",
    "Got the error: \n",
    "```\n",
    "AssertionError: Observation spaces for all agents must be identical. Perhaps SuperSuit's pad_observations wrapper can help (useage: `supersuit.aec_wrappers.pad_observations(env)`\n",
    "```\n",
    "\n",
    "# Run 2\n",
    "\n",
    "```\n",
    "AssertionError: homogenization only supports Discrete and Box spaces\n",
    "```\n",
    "\n",
    "# Run 3\n",
    "\n",
    "Same error\n",
    "```\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1050, in get_next_executor_event\n",
    "    future_result = ray.get(ready_future)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2291, in get\n",
    "    raise value\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::PPO.__init__() (pid=1879526, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 139, in __init__\n",
    "    self.add_workers(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 490, in add_workers\n",
    "    self.foreach_worker(lambda w: w.assert_healthy())\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 620, in foreach_worker\n",
    "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::RolloutWorker.__init__() (pid=1879573, ip=128.36.108.57, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa145f35d50>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 492, in __init__\n",
    "    self.env = env_creator(copy.deepcopy(self.env_context))\n",
    "  File \"/tmp/ipykernel_1861406/2067092441.py\", line 2, in <lambda>\n",
    "  File \"/tmp/ipykernel_1861406/841127696.py\", line 3, in env_creator\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/supersuit/multiagent_wrappers/padding_wrappers.py\", line 33, in pad_observations_v0\n",
    "    homogenize_ops.check_homogenize_spaces(spaces)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/supersuit/utils/action_transforms/homogenize_ops.py\", line 30, in check_homogenize_spaces\n",
    "    assert False, \"homogenization only supports Discrete and Box spaces\"\n",
    "AssertionError: homogenization only supports Discrete and Box spaces\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::PPO.__init__() (pid=1879526, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 414, in __init__\n",
    "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
    "    self.setup(copy.deepcopy(self.config))\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 549, in setup\n",
    "    raise e.args[0].args[2]\n",
    "AssertionError: homogenization only supports Discrete and Box spaces\n",
    "```\n",
    "\n",
    "i.e. I cannot use the SuperSuit wrapper to fix the issue of observation spaces for all agents needing to be identical.\n",
    "\n",
    "# Run 4\n",
    "\n",
    "Fixed the issue by making all observation spaces and action spaces the same for all agents.\n",
    "\n",
    "New issue:\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-12_17-37-17)\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1050, in get_next_executor_event\n",
    "    future_result = ray.get(ready_future)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2291, in get\n",
    "    raise value\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::PPO.__init__() (pid=499392, ip=128.36.232.21, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 139, in __init__\n",
    "    self.add_workers(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 490, in add_workers\n",
    "    self.foreach_worker(lambda w: w.assert_healthy())\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 620, in foreach_worker\n",
    "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::RolloutWorker.__init__() (pid=499452, ip=128.36.232.21, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f8059b28df0>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 567, in __init__\n",
    "    self.policy_dict = _determine_spaces_for_multi_agent_dict(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 2121, in _determine_spaces_for_multi_agent_dict\n",
    "    raise ValueError(\n",
    "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::PPO.__init__() (pid=499392, ip=128.36.232.21, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 414, in __init__\n",
    "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
    "    self.setup(copy.deepcopy(self.config))\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 549, in setup\n",
    "    raise e.args[0].args[2]\n",
    "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
    "```\n",
    "\n",
    "# Run 5\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-12_20-29-44)\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1050, in get_next_executor_event\n",
    "    future_result = ray.get(ready_future)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2291, in get\n",
    "    raise value\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::PPO.__init__() (pid=2054378, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 139, in __init__\n",
    "    self.add_workers(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 490, in add_workers\n",
    "    self.foreach_worker(lambda w: w.assert_healthy())\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 620, in foreach_worker\n",
    "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::RolloutWorker.__init__() (pid=2054502, ip=128.36.108.57, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f0abd339d50>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
    "    self._build_policy_map(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1882, in _build_policy_map\n",
    "    preprocessor = ModelCatalog.get_preprocessor_for_space(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/catalog.py\", line 815, in get_preprocessor_for_space\n",
    "    prep = cls(observation_space, options)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py\", line 42, in __init__\n",
    "    self._size = int(np.product(self.shape))\n",
    "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::PPO.__init__() (pid=2054378, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 414, in __init__\n",
    "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
    "    self.setup(copy.deepcopy(self.config))\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 549, in setup\n",
    "    raise e.args[0].args[2]\n",
    "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
    "```\n",
    "\n",
    "Note: the `Dict` space does not have a shape <https://github.com/openai/gym/blob/master/gym/spaces/dict.py#L118>\n",
    "\n",
    "Nope, the issue was I was using the wrong spaces from gymnasium.spaces, when instead RLlib assumes using gym.spaces spaces\n",
    "\n",
    "# Run 6\n",
    "\n",
    "```\n",
    "2022-12-12 21:59:59,682\tERROR trial_runner.py:993 -- Trial PPO_job_search_30f4a_00000: Error processing event.\n",
    "ray.exceptions.RayTaskError(ValueError): ray::PPO.train() (pid=1671497, ip=128.36.232.24, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
    "    raise skipped from exception_cause(skipped)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
    "    result = self.step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
    "    results, train_iter_ctx = self._run_one_training_iteration()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
    "    num_recreated += self.try_recover_from_step_attempt(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
    "    raise error\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
    "    results = self.training_step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
    "    train_batch = synchronous_parallel_sample(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
    "    sample_batches = ray.get(\n",
    "ray.exceptions.RayTaskError(ValueError): ray::RolloutWorker.sample() (pid=1671528, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f25d5759db0>)\n",
    "ValueError: The two structures don't have the same nested structure.\n",
    "\n",
    "First structure: type=dict str={'observation': {'candidate_obs': {'job_openings': {'employer_0': 1}, 'accepted_offer': {'employer_0': 0}, 'current_offers': {'employer_0': (0, 0)}, 'rejected_offers': {'employer_0': (0, 0)}, 'counter_offers': {'employer_0': (0, 0)}}, 'employer_obs': {'candidate_strengths': {'candidate_0': 0}, 'job_applicants': {'candidate_0': 0}, 'outstanding_offers': {'candidate_0': (0, 0)}, 'accepted_offers': {'candidate_0': 0}, 'declined_offers': {'candidate_0': (0, 0)}, 'counter_offers': {'candidate_0': (0, 0)}, 'rejected_offers': {'candidate_0': (0, 0)}, 'remaining_budget': 100}}, 'action_mask': array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0])}\n",
    "\n",
    "Second structure: type=OrderedDict str=OrderedDict([('candidate_obs', OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])), ('employer_obs', OrderedDict([('accepted_offers', OrderedDict([('candidate_0', 1)])), ('candidate_strengths', OrderedDict([('candidate_0', 79)])), ('counter_offers', OrderedDict([('candidate_0', (66, 5))])), ('declined_offers', OrderedDict([('candidate_0', (1, 7))])), ('job_applicants', OrderedDict([('candidate_0', 1)])), ('outstanding_offers', OrderedDict([('candidate_0', (28, 0))])), ('rejected_offers', OrderedDict([('candidate_0', (0, 4))])), ('remaining_budget', 96)]))])\n",
    "\n",
    "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])\" is a sequence, while substructure \"type=ndarray str=[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0]\" is not\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::RolloutWorker.sample() (pid=1671528, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f25d5759db0>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
    "    batches = [self.input_reader.next()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
    "    batches = [self.get_data()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
    "    item = next(self._env_runner)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 671, in _env_runner\n",
    "    active_envs, to_eval, outputs = _process_observations(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 922, in _process_observations\n",
    "    prep_obs = preprocessor.transform(raw_obs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py\", line 283, in transform\n",
    "    self.check_shape(observation)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py\", line 69, in check_shape\n",
    "    observation = convert_element_to_space_type(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/utils/spaces/space_utils.py\", line 359, in convert_element_to_space_type\n",
    "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/tree/__init__.py\", line 428, in map_structure\n",
    "    assert_same_structure(structures[0], other, check_types=check_types)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/tree/__init__.py\", line 284, in assert_same_structure\n",
    "    raise type(e)(\"%s\\n\"\n",
    "ValueError: The two structures don't have the same nested structure.\n",
    "\n",
    "First structure: type=dict str={'observation': {'candidate_obs': {'job_openings': {'employer_0': 1}, 'accepted_offer': {'employer_0': 0}, 'current_offers': {'employer_0': (0, 0)}, 'rejected_offers': {'employer_0': (0, 0)}, 'counter_offers': {'employer_0': (0, 0)}}, 'employer_obs': {'candidate_strengths': {'candidate_0': 0}, 'job_applicants': {'candidate_0': 0}, 'outstanding_offers': {'candidate_0': (0, 0)}, 'accepted_offers': {'candidate_0': 0}, 'declined_offers': {'candidate_0': (0, 0)}, 'counter_offers': {'candidate_0': (0, 0)}, 'rejected_offers': {'candidate_0': (0, 0)}, 'remaining_budget': 100}}, 'action_mask': array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0])}\n",
    "\n",
    "Second structure: type=OrderedDict str=OrderedDict([('candidate_obs', OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])), ('employer_obs', OrderedDict([('accepted_offers', OrderedDict([('candidate_0', 1)])), ('candidate_strengths', OrderedDict([('candidate_0', 79)])), ('counter_offers', OrderedDict([('candidate_0', (66, 5))])), ('declined_offers', OrderedDict([('candidate_0', (1, 7))])), ('job_applicants', OrderedDict([('candidate_0', 1)])), ('outstanding_offers', OrderedDict([('candidate_0', (28, 0))])), ('rejected_offers', OrderedDict([('candidate_0', (0, 4))])), ('remaining_budget', 96)]))])\n",
    "\n",
    "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])\" is a sequence, while substructure \"type=ndarray str=[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0]\" is not\n",
    "Entire first structure:\n",
    "{'observation': {'candidate_obs': {'job_openings': {'employer_0': .}, 'accepted_offer': {'employer_0': .}, 'current_offers': {'employer_0': (., .)}, 'rejected_offers': {'employer_0': (., .)}, 'counter_offers': {'employer_0': (., .)}}, 'employer_obs': {'candidate_strengths': {'candidate_0': .}, 'job_applicants': {'candidate_0': .}, 'outstanding_offers': {'candidate_0': (., .)}, 'accepted_offers': {'candidate_0': .}, 'declined_offers': {'candidate_0': (., .)}, 'counter_offers': {'candidate_0': (., .)}, 'rejected_offers': {'candidate_0': (., .)}, 'remaining_budget': .}}, 'action_mask': .}\n",
    "Entire second structure:\n",
    "OrderedDict([('candidate_obs', OrderedDict([('accepted_offer', OrderedDict([('employer_0', .)])), ('counter_offers', OrderedDict([('employer_0', (., .))])), ('current_offers', OrderedDict([('employer_0', (., .))])), ('job_openings', OrderedDict([('employer_0', .)])), ('rejected_offers', OrderedDict([('employer_0', (., .))]))])), ('employer_obs', OrderedDict([('accepted_offers', OrderedDict([('candidate_0', .)])), ('candidate_strengths', OrderedDict([('candidate_0', .)])), ('counter_offers', OrderedDict([('candidate_0', (., .))])), ('declined_offers', OrderedDict([('candidate_0', (., .))])), ('job_applicants', OrderedDict([('candidate_0', .)])), ('outstanding_offers', OrderedDict([('candidate_0', (., .))])), ('rejected_offers', OrderedDict([('candidate_0', (., .))])), ('remaining_budget', .)]))])\n",
    "```\n",
    "\n",
    "# Run 7\n",
    "\n",
    "Issues with observation/action_mask dictionary structure. Fixed by updating the observation space definition to also include the action mask.\n",
    "\n",
    "# Run 8\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-13_13-53-45)\n",
    "ray::PPO.train() (pid=2035053, ip=128.36.232.24, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
    "    raise skipped from exception_cause(skipped)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
    "    result = self.step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
    "    results, train_iter_ctx = self._run_one_training_iteration()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
    "    num_recreated += self.try_recover_from_step_attempt(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
    "    raise error\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
    "    results = self.training_step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
    "    train_batch = synchronous_parallel_sample(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
    "    sample_batches = ray.get(\n",
    "ray.exceptions.RayTaskError(ValueError): ray::RolloutWorker.sample() (pid=2035175, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa1c5255d80>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
    "    batches = [self.input_reader.next()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
    "    batches = [self.get_data()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
    "    item = next(self._env_runner)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
    "    base_env.send_actions(actions_to_send)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 615, in send_actions\n",
    "    raise e\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 608, in send_actions\n",
    "    obs, rewards, dones, infos = env.step(agent_dict)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py\", line 184, in step\n",
    "    obss, rews, dones, infos = self.par_env.step(action_dict)\n",
    "ValueError: too many values to unpack (expected 4)\n",
    "```\n",
    "\n",
    "# Run 9\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-13_14-18-31)\n",
    "ray::PPO.train() (pid=2045783, ip=128.36.232.24, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
    "    raise skipped from exception_cause(skipped)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
    "    result = self.step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
    "    results, train_iter_ctx = self._run_one_training_iteration()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
    "    num_recreated += self.try_recover_from_step_attempt(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
    "    raise error\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
    "    results = self.training_step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
    "    train_batch = synchronous_parallel_sample(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
    "    sample_batches = ray.get(\n",
    "ray.exceptions.RayTaskError(KeyError): ray::RolloutWorker.sample() (pid=2045906, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f68b792dde0>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
    "    batches = [self.input_reader.next()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
    "    batches = [self.get_data()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
    "    item = next(self._env_runner)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
    "    base_env.send_actions(actions_to_send)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 615, in send_actions\n",
    "    raise e\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 608, in send_actions\n",
    "    obs, rewards, dones, infos = env.step(agent_dict)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py\", line 184, in step\n",
    "    obss, rews, dones, infos = self.par_env.step(action_dict)\n",
    "  File \"/home/accts/ahc49/csec491/salary-negotation/environment/job_search_environment.py\", line 394, in step\n",
    "    action, target_index, new_offer_value, new_deadline = actions[agent]\n",
    "KeyError: 'employer_0'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0a4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
