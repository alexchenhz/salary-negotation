{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f091c0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import environment.job_search_environment as job_search_env\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from supersuit import pad_observations_v0, pad_action_space_v0\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe3b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, Dict, Tuple, Box\n",
    "\n",
    "from gym.spaces.utils import flatten, flatdim, flatten_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45796123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is working on the Zoo, but not on my local machine (M1 compatibility issues)\n",
    "from ray.rllib.algorithms.ppo import PPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83500be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3a74d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.rllib.models.modelv2 import restore_original_dimensions\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.tune.registry import register_env\n",
    "import torch\n",
    "from torch import nn\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.torch_utils import FLOAT_MIN\n",
    "from ray.rllib.models.preprocessors import Preprocessor, DictFlatteningPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1, tf, tfv = try_import_tf()\n",
    "torch, _ = try_import_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fb27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In order to deal with the Dictionary space, need to pass a custom model to RLlib.\n",
    "See: https://medium.com/@nima.siboni/rllib-with-dictionary-state-baa06b64470f\n",
    "\"\"\"\n",
    "class CandidateModelV0(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name, **kwargs):\n",
    "        orig_space = getattr(obs_space, \"original_space\", obs_space)\n",
    "        assert (\n",
    "            isinstance(orig_space, Dict)\n",
    "            and \"action_mask\" in orig_space.spaces\n",
    "            and \"observation\" in orig_space.spaces\n",
    "        )\n",
    "        print(\"Orig space\")\n",
    "        print(orig_space)\n",
    "        print(\"Obs space\")\n",
    "        print(obs_space)\n",
    "        print(\"Flattened obs space\")\n",
    "        print(flatten_space(orig_space[\"observation\"]))\n",
    "        print(\"Act space\")\n",
    "        print(action_space)\n",
    "        print(\"Num outputs\")\n",
    "        print(num_outputs)\n",
    "        print(\"Model config\") \n",
    "        print(model_config)\n",
    "        \n",
    "#         self.orig_space = orig_space\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name, **kwargs)\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.internal_model = TorchFC(\n",
    "            flatten_space(orig_space[\"observation\"]),\n",
    "            action_space,\n",
    "            num_outputs,\n",
    "            model_config,\n",
    "            name + \"_internal\",\n",
    "        )\n",
    "        # disable action masking --> will likely lead to invalid actions\n",
    "        self.no_masking = False\n",
    "        if \"no_masking\" in model_config[\"custom_model_config\"]:\n",
    "            self.no_masking = model_config[\"custom_model_config\"][\"no_masking\"]\n",
    "        \n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Extract the available actions tensor from the observation.\n",
    "        action_mask = input_dict[\"obs\"][\"action_mask\"]\n",
    "        \n",
    "#         print(\"original_model\")\n",
    "        \n",
    "#         print(input_dict[\"obs_flat\"][:,self.num_outputs:])\n",
    "#         print(input_dict[\"obs_flat\"][:,self.num_outputs:].size())\n",
    "        \n",
    "        # Compute the unmasked logits.\n",
    "        logits, _ = self.internal_model({\"obs\": input_dict[\"obs_flat\"][:,self.num_outputs:]})\n",
    "        \n",
    "        \n",
    "#         print(\"logits:\\n\", logits)\n",
    "        \n",
    "        \n",
    "        # If action masking is disabled, directly return unmasked logits\n",
    "        if self.no_masking:\n",
    "            return logits, state\n",
    "\n",
    "        # Convert action_mask into a [0.0 || -inf]-type mask.\n",
    "        inf_mask = torch.clamp(torch.log(action_mask), min=FLOAT_MIN)\n",
    "        masked_logits = logits + inf_mask\n",
    "\n",
    "#         print(\"masks:\\n\", inf_mask, \"\\n\", masked_logits)\n",
    "        \n",
    "        # Return masked logits.\n",
    "        return masked_logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self.internal_model.value_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(args):\n",
    "    env = job_search_env.env()\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e48f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"job_search_env\"\n",
    "register_env(env_name, lambda config: ParallelPettingZooEnv(env_creator(config)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ca8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"CandidateModelV0\", CandidateModelV0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use policy_map to map different policies to candidate and employer agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need a custom preprocessor for the custom model with action masking\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=env_name, clip_actions=False)\n",
    "    .debugging(log_level=\"ERROR\")\n",
    "    .framework(framework=\"torch\")\n",
    "    .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    "\n",
    "    .training(model={\n",
    "                        \"custom_model\": CandidateModelV0,\n",
    "                        \"custom_model_config\": {},\n",
    "    })\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_env.env().agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b778a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"observation_space\"] = job_search_env.env().observation_space(\"candidate_0\")\n",
    "config[\"action_space\"] = job_search_env.env().action_space(\"candidate_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1efed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"observation_space\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e32e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"action_space\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4594e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa733c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    \"PPO\",\n",
    "    name=\"PPO\",\n",
    "    stop={\"timesteps_total\": 10000},\n",
    "    checkpoint_freq=10,\n",
    "    local_dir=\"~/ray_results/\" + env_name,\n",
    "    config=config,\n",
    "    num_samples=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8cfa6",
   "metadata": {},
   "source": [
    "### Use gym.space instead of gymnasium.spaces to fix this AHHHHH\n",
    "```\n",
    "from gym.spaces import Discrete, Dict, Tuple\n",
    "\n",
    "from gym.spaces.utils import flatten, flatdim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6119029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, Dict, Tuple, Box\n",
    "\n",
    "from gym.spaces.utils import flatten, flatdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5ad4d823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(10)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = Dict({\"test\": Discrete(10)})\n",
    "space[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "03395401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(flatdim(Tuple((Discrete(4), Discrete(2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3bc19a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66815686, 0.8099814 , 0.6728993 , 0.3833307 , 0.83226   ,\n",
       "       0.01675155, 0.36507058, 0.9905923 , 0.5650419 , 0.37177613],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0.0, 1.0, shape=(10,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5640cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8192585 , 0.21756119, 0.7595661 , 0.06519676, 0.5593857 ,\n",
       "       0.6580883 , 0.89733326, 0.01662113, 0.39561164, 0.0882608 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(0.0, 1, shape=(10,)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "335253fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "09647c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(Tuple((Discrete(10), Discrete(5))), (0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d024f0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_mask = torch.from_numpy(np.array([1, 0]))\n",
    "action_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "46f4964b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00, -3.4000e+38])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_mask = torch.clamp(torch.log(action_mask), min=FLOAT_MIN)\n",
    "inf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e682924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+00, -3.4000e+38])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([1,1])\n",
    "logits + inf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f502255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0, 1]) + torch.tensor([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb93663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c4d728",
   "metadata": {},
   "source": [
    "# Run 1\n",
    "Got the error: \n",
    "```\n",
    "AssertionError: Observation spaces for all agents must be identical. Perhaps SuperSuit's pad_observations wrapper can help (useage: `supersuit.aec_wrappers.pad_observations(env)`\n",
    "```\n",
    "\n",
    "# Run 2\n",
    "\n",
    "```\n",
    "AssertionError: homogenization only supports Discrete and Box spaces\n",
    "```\n",
    "\n",
    "# Run 3\n",
    "\n",
    "Same error\n",
    "```\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1050, in get_next_executor_event\n",
    "    future_result = ray.get(ready_future)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2291, in get\n",
    "    raise value\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::PPO.__init__() (pid=1879526, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 139, in __init__\n",
    "    self.add_workers(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 490, in add_workers\n",
    "    self.foreach_worker(lambda w: w.assert_healthy())\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 620, in foreach_worker\n",
    "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::RolloutWorker.__init__() (pid=1879573, ip=128.36.108.57, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa145f35d50>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 492, in __init__\n",
    "    self.env = env_creator(copy.deepcopy(self.env_context))\n",
    "  File \"/tmp/ipykernel_1861406/2067092441.py\", line 2, in <lambda>\n",
    "  File \"/tmp/ipykernel_1861406/841127696.py\", line 3, in env_creator\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/supersuit/multiagent_wrappers/padding_wrappers.py\", line 33, in pad_observations_v0\n",
    "    homogenize_ops.check_homogenize_spaces(spaces)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/supersuit/utils/action_transforms/homogenize_ops.py\", line 30, in check_homogenize_spaces\n",
    "    assert False, \"homogenization only supports Discrete and Box spaces\"\n",
    "AssertionError: homogenization only supports Discrete and Box spaces\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::PPO.__init__() (pid=1879526, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 414, in __init__\n",
    "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
    "    self.setup(copy.deepcopy(self.config))\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 549, in setup\n",
    "    raise e.args[0].args[2]\n",
    "AssertionError: homogenization only supports Discrete and Box spaces\n",
    "```\n",
    "\n",
    "i.e. I cannot use the SuperSuit wrapper to fix the issue of observation spaces for all agents needing to be identical.\n",
    "\n",
    "# Run 4\n",
    "\n",
    "Fixed the issue by making all observation spaces and action spaces the same for all agents.\n",
    "\n",
    "New issue:\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-12_17-37-17)\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1050, in get_next_executor_event\n",
    "    future_result = ray.get(ready_future)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2291, in get\n",
    "    raise value\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::PPO.__init__() (pid=499392, ip=128.36.232.21, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 139, in __init__\n",
    "    self.add_workers(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 490, in add_workers\n",
    "    self.foreach_worker(lambda w: w.assert_healthy())\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 620, in foreach_worker\n",
    "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::RolloutWorker.__init__() (pid=499452, ip=128.36.232.21, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f8059b28df0>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 567, in __init__\n",
    "    self.policy_dict = _determine_spaces_for_multi_agent_dict(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 2121, in _determine_spaces_for_multi_agent_dict\n",
    "    raise ValueError(\n",
    "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::PPO.__init__() (pid=499392, ip=128.36.232.21, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 414, in __init__\n",
    "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
    "    self.setup(copy.deepcopy(self.config))\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 549, in setup\n",
    "    raise e.args[0].args[2]\n",
    "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
    "```\n",
    "\n",
    "# Run 5\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-12_20-29-44)\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1050, in get_next_executor_event\n",
    "    future_result = ray.get(ready_future)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2291, in get\n",
    "    raise value\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::PPO.__init__() (pid=2054378, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 139, in __init__\n",
    "    self.add_workers(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 490, in add_workers\n",
    "    self.foreach_worker(lambda w: w.assert_healthy())\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py\", line 620, in foreach_worker\n",
    "    remote_results = ray.get([w.apply.remote(func) for w in self.remote_workers()])\n",
    "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, ray::RolloutWorker.__init__() (pid=2054502, ip=128.36.108.57, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f0abd339d50>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 625, in __init__\n",
    "    self._build_policy_map(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1882, in _build_policy_map\n",
    "    preprocessor = ModelCatalog.get_preprocessor_for_space(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/catalog.py\", line 815, in get_preprocessor_for_space\n",
    "    prep = cls(observation_space, options)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py\", line 42, in __init__\n",
    "    self._size = int(np.product(self.shape))\n",
    "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::PPO.__init__() (pid=2054378, ip=128.36.108.57, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 414, in __init__\n",
    "    super().__init__(config=config, logger_creator=logger_creator, **kwargs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
    "    self.setup(copy.deepcopy(self.config))\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 549, in setup\n",
    "    raise e.args[0].args[2]\n",
    "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
    "```\n",
    "\n",
    "Note: the `Dict` space does not have a shape <https://github.com/openai/gym/blob/master/gym/spaces/dict.py#L118>\n",
    "\n",
    "Nope, the issue was I was using the wrong spaces from gymnasium.spaces, when instead RLlib assumes using gym.spaces spaces\n",
    "\n",
    "# Run 6\n",
    "\n",
    "```\n",
    "2022-12-12 21:59:59,682\tERROR trial_runner.py:993 -- Trial PPO_job_search_30f4a_00000: Error processing event.\n",
    "ray.exceptions.RayTaskError(ValueError): ray::PPO.train() (pid=1671497, ip=128.36.232.24, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
    "    raise skipped from exception_cause(skipped)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
    "    result = self.step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
    "    results, train_iter_ctx = self._run_one_training_iteration()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
    "    num_recreated += self.try_recover_from_step_attempt(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
    "    raise error\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
    "    results = self.training_step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
    "    train_batch = synchronous_parallel_sample(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
    "    sample_batches = ray.get(\n",
    "ray.exceptions.RayTaskError(ValueError): ray::RolloutWorker.sample() (pid=1671528, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f25d5759db0>)\n",
    "ValueError: The two structures don't have the same nested structure.\n",
    "\n",
    "First structure: type=dict str={'observation': {'candidate_obs': {'job_openings': {'employer_0': 1}, 'accepted_offer': {'employer_0': 0}, 'current_offers': {'employer_0': (0, 0)}, 'rejected_offers': {'employer_0': (0, 0)}, 'counter_offers': {'employer_0': (0, 0)}}, 'employer_obs': {'candidate_strengths': {'candidate_0': 0}, 'job_applicants': {'candidate_0': 0}, 'outstanding_offers': {'candidate_0': (0, 0)}, 'accepted_offers': {'candidate_0': 0}, 'declined_offers': {'candidate_0': (0, 0)}, 'counter_offers': {'candidate_0': (0, 0)}, 'rejected_offers': {'candidate_0': (0, 0)}, 'remaining_budget': 100}}, 'action_mask': array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0])}\n",
    "\n",
    "Second structure: type=OrderedDict str=OrderedDict([('candidate_obs', OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])), ('employer_obs', OrderedDict([('accepted_offers', OrderedDict([('candidate_0', 1)])), ('candidate_strengths', OrderedDict([('candidate_0', 79)])), ('counter_offers', OrderedDict([('candidate_0', (66, 5))])), ('declined_offers', OrderedDict([('candidate_0', (1, 7))])), ('job_applicants', OrderedDict([('candidate_0', 1)])), ('outstanding_offers', OrderedDict([('candidate_0', (28, 0))])), ('rejected_offers', OrderedDict([('candidate_0', (0, 4))])), ('remaining_budget', 96)]))])\n",
    "\n",
    "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])\" is a sequence, while substructure \"type=ndarray str=[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0]\" is not\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ray::RolloutWorker.sample() (pid=1671528, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f25d5759db0>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
    "    batches = [self.input_reader.next()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
    "    batches = [self.get_data()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
    "    item = next(self._env_runner)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 671, in _env_runner\n",
    "    active_envs, to_eval, outputs = _process_observations(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 922, in _process_observations\n",
    "    prep_obs = preprocessor.transform(raw_obs)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py\", line 283, in transform\n",
    "    self.check_shape(observation)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py\", line 69, in check_shape\n",
    "    observation = convert_element_to_space_type(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/utils/spaces/space_utils.py\", line 359, in convert_element_to_space_type\n",
    "    return tree.map_structure(map_, element, sampled_element, check_types=False)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/tree/__init__.py\", line 428, in map_structure\n",
    "    assert_same_structure(structures[0], other, check_types=check_types)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/tree/__init__.py\", line 284, in assert_same_structure\n",
    "    raise type(e)(\"%s\\n\"\n",
    "ValueError: The two structures don't have the same nested structure.\n",
    "\n",
    "First structure: type=dict str={'observation': {'candidate_obs': {'job_openings': {'employer_0': 1}, 'accepted_offer': {'employer_0': 0}, 'current_offers': {'employer_0': (0, 0)}, 'rejected_offers': {'employer_0': (0, 0)}, 'counter_offers': {'employer_0': (0, 0)}}, 'employer_obs': {'candidate_strengths': {'candidate_0': 0}, 'job_applicants': {'candidate_0': 0}, 'outstanding_offers': {'candidate_0': (0, 0)}, 'accepted_offers': {'candidate_0': 0}, 'declined_offers': {'candidate_0': (0, 0)}, 'counter_offers': {'candidate_0': (0, 0)}, 'rejected_offers': {'candidate_0': (0, 0)}, 'remaining_budget': 100}}, 'action_mask': array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0])}\n",
    "\n",
    "Second structure: type=OrderedDict str=OrderedDict([('candidate_obs', OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])), ('employer_obs', OrderedDict([('accepted_offers', OrderedDict([('candidate_0', 1)])), ('candidate_strengths', OrderedDict([('candidate_0', 79)])), ('counter_offers', OrderedDict([('candidate_0', (66, 5))])), ('declined_offers', OrderedDict([('candidate_0', (1, 7))])), ('job_applicants', OrderedDict([('candidate_0', 1)])), ('outstanding_offers', OrderedDict([('candidate_0', (28, 0))])), ('rejected_offers', OrderedDict([('candidate_0', (0, 4))])), ('remaining_budget', 96)]))])\n",
    "\n",
    "More specifically: Substructure \"type=OrderedDict str=OrderedDict([('accepted_offer', OrderedDict([('employer_0', 56)])), ('counter_offers', OrderedDict([('employer_0', (99, 8))])), ('current_offers', OrderedDict([('employer_0', (28, 10))])), ('job_openings', OrderedDict([('employer_0', 1)])), ('rejected_offers', OrderedDict([('employer_0', (1, 49))]))])\" is a sequence, while substructure \"type=ndarray str=[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0]\" is not\n",
    "Entire first structure:\n",
    "{'observation': {'candidate_obs': {'job_openings': {'employer_0': .}, 'accepted_offer': {'employer_0': .}, 'current_offers': {'employer_0': (., .)}, 'rejected_offers': {'employer_0': (., .)}, 'counter_offers': {'employer_0': (., .)}}, 'employer_obs': {'candidate_strengths': {'candidate_0': .}, 'job_applicants': {'candidate_0': .}, 'outstanding_offers': {'candidate_0': (., .)}, 'accepted_offers': {'candidate_0': .}, 'declined_offers': {'candidate_0': (., .)}, 'counter_offers': {'candidate_0': (., .)}, 'rejected_offers': {'candidate_0': (., .)}, 'remaining_budget': .}}, 'action_mask': .}\n",
    "Entire second structure:\n",
    "OrderedDict([('candidate_obs', OrderedDict([('accepted_offer', OrderedDict([('employer_0', .)])), ('counter_offers', OrderedDict([('employer_0', (., .))])), ('current_offers', OrderedDict([('employer_0', (., .))])), ('job_openings', OrderedDict([('employer_0', .)])), ('rejected_offers', OrderedDict([('employer_0', (., .))]))])), ('employer_obs', OrderedDict([('accepted_offers', OrderedDict([('candidate_0', .)])), ('candidate_strengths', OrderedDict([('candidate_0', .)])), ('counter_offers', OrderedDict([('candidate_0', (., .))])), ('declined_offers', OrderedDict([('candidate_0', (., .))])), ('job_applicants', OrderedDict([('candidate_0', .)])), ('outstanding_offers', OrderedDict([('candidate_0', (., .))])), ('rejected_offers', OrderedDict([('candidate_0', (., .))])), ('remaining_budget', .)]))])\n",
    "```\n",
    "\n",
    "# Run 7\n",
    "\n",
    "Issues with observation/action_mask dictionary structure. Fixed by updating the observation space definition to also include the action mask.\n",
    "\n",
    "# Run 8\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-13_13-53-45)\n",
    "ray::PPO.train() (pid=2035053, ip=128.36.232.24, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
    "    raise skipped from exception_cause(skipped)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
    "    result = self.step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
    "    results, train_iter_ctx = self._run_one_training_iteration()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
    "    num_recreated += self.try_recover_from_step_attempt(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
    "    raise error\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
    "    results = self.training_step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
    "    train_batch = synchronous_parallel_sample(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
    "    sample_batches = ray.get(\n",
    "ray.exceptions.RayTaskError(ValueError): ray::RolloutWorker.sample() (pid=2035175, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa1c5255d80>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
    "    batches = [self.input_reader.next()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
    "    batches = [self.get_data()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
    "    item = next(self._env_runner)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
    "    base_env.send_actions(actions_to_send)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 615, in send_actions\n",
    "    raise e\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 608, in send_actions\n",
    "    obs, rewards, dones, infos = env.step(agent_dict)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py\", line 184, in step\n",
    "    obss, rews, dones, infos = self.par_env.step(action_dict)\n",
    "ValueError: too many values to unpack (expected 4)\n",
    "```\n",
    "\n",
    "# Run 9\n",
    "\n",
    "```\n",
    "Failure # 1 (occurred at 2022-12-13_14-18-31)\n",
    "ray::PPO.train() (pid=2045783, ip=128.36.232.24, repr=PPO)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
    "    raise skipped from exception_cause(skipped)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 352, in train\n",
    "    result = self.step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 772, in step\n",
    "    results, train_iter_ctx = self._run_one_training_iteration()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2953, in _run_one_training_iteration\n",
    "    num_recreated += self.try_recover_from_step_attempt(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2617, in try_recover_from_step_attempt\n",
    "    raise error\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py\", line 2948, in _run_one_training_iteration\n",
    "    results = self.training_step()\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 408, in training_step\n",
    "    train_batch = synchronous_parallel_sample(\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 100, in synchronous_parallel_sample\n",
    "    sample_batches = ray.get(\n",
    "ray.exceptions.RayTaskError(KeyError): ray::RolloutWorker.sample() (pid=2045906, ip=128.36.232.24, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f68b792dde0>)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 828, in sample\n",
    "    batches = [self.input_reader.next()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 92, in next\n",
    "    batches = [self.get_data()]\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 285, in get_data\n",
    "    item = next(self._env_runner)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 721, in _env_runner\n",
    "    base_env.send_actions(actions_to_send)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 615, in send_actions\n",
    "    raise e\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 608, in send_actions\n",
    "    obs, rewards, dones, infos = env.step(agent_dict)\n",
    "  File \"/home/accts/ahc49/.local/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py\", line 184, in step\n",
    "    obss, rews, dones, infos = self.par_env.step(action_dict)\n",
    "  File \"/home/accts/ahc49/csec491/salary-negotation/environment/job_search_environment.py\", line 394, in step\n",
    "    action, target_index, new_offer_value, new_deadline = actions[agent]\n",
    "KeyError: 'employer_0'\n",
    "```\n",
    "\n",
    "I didn't actually specify in the config to use the custom model sigh :(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c65841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
