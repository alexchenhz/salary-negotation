{
  "_disable_action_flattening": false,
  "_disable_execution_plan_api": true,
  "_disable_preprocessor_api": false,
  "_fake_gpus": false,
  "_tf_policy_handles_more_than_one_loss": false,
  "action_space": "Tuple(Discrete(5), Discrete(5), Discrete(101), Discrete(11))",
  "actions_in_input_normalized": false,
  "always_attach_evaluation_results": false,
  "batch_mode": "truncate_episodes",
  "buffer_size": -1,
  "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
  "clip_actions": false,
  "clip_param": 0.3,
  "clip_rewards": null,
  "collect_metrics_timeout": -1,
  "compress_observations": false,
  "create_env_on_driver": false,
  "custom_eval_function": null,
  "custom_resources_per_worker": {},
  "disable_env_checking": false,
  "eager_max_retraces": 20,
  "eager_tracing": false,
  "enable_async_evaluation": false,
  "enable_connectors": false,
  "enable_tf1_exec_eagerly": false,
  "entropy_coeff": 0.0,
  "entropy_coeff_schedule": null,
  "env": "job_search_env",
  "env_config": {},
  "env_task_fn": null,
  "evaluation_config": {},
  "evaluation_duration": 10,
  "evaluation_duration_unit": "episodes",
  "evaluation_interval": null,
  "evaluation_num_episodes": -1,
  "evaluation_num_workers": 0,
  "evaluation_parallel_to_training": false,
  "evaluation_sample_timeout_s": 180.0,
  "exploration_config": {
    "type": "StochasticSampling"
  },
  "explore": true,
  "export_native_model_files": false,
  "extra_python_environs_for_driver": {},
  "extra_python_environs_for_worker": {},
  "fake_sampler": false,
  "framework": "torch",
  "gamma": 0.99,
  "grad_clip": null,
  "horizon": null,
  "ignore_worker_failures": false,
  "in_evaluation": false,
  "input": "sampler",
  "input_config": {},
  "input_evaluation": -1,
  "keep_per_episode_custom_metrics": false,
  "kl_coeff": 0.2,
  "kl_target": 0.01,
  "lambda": 1.0,
  "learning_starts": -1,
  "local_tf_session_args": {
    "inter_op_parallelism_threads": 8,
    "intra_op_parallelism_threads": 8
  },
  "log_level": "ERROR",
  "log_sys_usage": true,
  "logger_config": null,
  "logger_creator": null,
  "lr": 5e-05,
  "lr_schedule": null,
  "metrics_episode_collection_timeout_s": 60.0,
  "metrics_num_episodes_for_smoothing": 100,
  "metrics_smoothing_episodes": -1,
  "min_iter_time_s": -1,
  "min_sample_timesteps_per_iteration": 0,
  "min_sample_timesteps_per_reporting": -1,
  "min_time_s_per_iteration": null,
  "min_time_s_per_reporting": -1,
  "min_train_timesteps_per_iteration": 0,
  "min_train_timesteps_per_reporting": -1,
  "model": {
    "custom_model": "<class 'models.job_search_model.JobSearchModelV0'>",
    "custom_model_config": {}
  },
  "monitor": -1,
  "multiagent": {
    "count_steps_by": "env_steps",
    "observation_fn": null,
    "policies": {
      "candidate_policy": [
        "<class 'ray.rllib.algorithms.ppo.ppo_torch_policy.PPOTorchPolicy'>",
        "Dict(action_mask:Box(0.0, 1.0, (122,), float32), observation:Dict(candidate_obs:Dict(accepted_offer:Dict(employer_0:Discrete(101), employer_1:Discrete(101), employer_2:Discrete(101), employer_3:Discrete(101), employer_4:Discrete(101)), counter_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11)), employer_1:Tuple(Discrete(101), Discrete(11)), employer_2:Tuple(Discrete(101), Discrete(11)), employer_3:Tuple(Discrete(101), Discrete(11)), employer_4:Tuple(Discrete(101), Discrete(11))), current_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11)), employer_1:Tuple(Discrete(101), Discrete(11)), employer_2:Tuple(Discrete(101), Discrete(11)), employer_3:Tuple(Discrete(101), Discrete(11)), employer_4:Tuple(Discrete(101), Discrete(11))), job_openings:Dict(employer_0:Discrete(2), employer_1:Discrete(2), employer_2:Discrete(2), employer_3:Discrete(2), employer_4:Discrete(2)), rejected_offers:Dict(employer_0:Tuple(Discrete(2), Discrete(101)), employer_1:Tuple(Discrete(2), Discrete(101)), employer_2:Tuple(Discrete(2), Discrete(101)), employer_3:Tuple(Discrete(2), Discrete(101)), employer_4:Tuple(Discrete(2), Discrete(101)))), employer_obs:Dict(accepted_offers:Dict(candidate_0:Discrete(2), candidate_1:Discrete(2), candidate_2:Discrete(2), candidate_3:Discrete(2), candidate_4:Discrete(2)), candidate_strengths:Dict(candidate_0:Discrete(101), candidate_1:Discrete(101), candidate_2:Discrete(101), candidate_3:Discrete(101), candidate_4:Discrete(101)), counter_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11)), candidate_1:Tuple(Discrete(101), Discrete(11)), candidate_2:Tuple(Discrete(101), Discrete(11)), candidate_3:Tuple(Discrete(101), Discrete(11)), candidate_4:Tuple(Discrete(101), Discrete(11))), declined_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101)), candidate_1:Tuple(Discrete(2), Discrete(101)), candidate_2:Tuple(Discrete(2), Discrete(101)), candidate_3:Tuple(Discrete(2), Discrete(101)), candidate_4:Tuple(Discrete(2), Discrete(101))), job_applicants:Dict(candidate_0:Discrete(2), candidate_1:Discrete(2), candidate_2:Discrete(2), candidate_3:Discrete(2), candidate_4:Discrete(2)), outstanding_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11)), candidate_1:Tuple(Discrete(101), Discrete(11)), candidate_2:Tuple(Discrete(101), Discrete(11)), candidate_3:Tuple(Discrete(101), Discrete(11)), candidate_4:Tuple(Discrete(101), Discrete(11))), rejected_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101)), candidate_1:Tuple(Discrete(2), Discrete(101)), candidate_2:Tuple(Discrete(2), Discrete(101)), candidate_3:Tuple(Discrete(2), Discrete(101)), candidate_4:Tuple(Discrete(2), Discrete(101))), remaining_budget:Discrete(101))))",
        "Tuple(Discrete(5), Discrete(5), Discrete(101), Discrete(11))",
        {
          "model": {
            "custom_model": "CandidateModel",
            "custom_model_config": {}
          }
        }
      ],
      "employer_policy": [
        "<class 'ray.rllib.algorithms.ppo.ppo_torch_policy.PPOTorchPolicy'>",
        "Dict(action_mask:Box(0.0, 1.0, (122,), float32), observation:Dict(candidate_obs:Dict(accepted_offer:Dict(employer_0:Discrete(101), employer_1:Discrete(101), employer_2:Discrete(101), employer_3:Discrete(101), employer_4:Discrete(101)), counter_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11)), employer_1:Tuple(Discrete(101), Discrete(11)), employer_2:Tuple(Discrete(101), Discrete(11)), employer_3:Tuple(Discrete(101), Discrete(11)), employer_4:Tuple(Discrete(101), Discrete(11))), current_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11)), employer_1:Tuple(Discrete(101), Discrete(11)), employer_2:Tuple(Discrete(101), Discrete(11)), employer_3:Tuple(Discrete(101), Discrete(11)), employer_4:Tuple(Discrete(101), Discrete(11))), job_openings:Dict(employer_0:Discrete(2), employer_1:Discrete(2), employer_2:Discrete(2), employer_3:Discrete(2), employer_4:Discrete(2)), rejected_offers:Dict(employer_0:Tuple(Discrete(2), Discrete(101)), employer_1:Tuple(Discrete(2), Discrete(101)), employer_2:Tuple(Discrete(2), Discrete(101)), employer_3:Tuple(Discrete(2), Discrete(101)), employer_4:Tuple(Discrete(2), Discrete(101)))), employer_obs:Dict(accepted_offers:Dict(candidate_0:Discrete(2), candidate_1:Discrete(2), candidate_2:Discrete(2), candidate_3:Discrete(2), candidate_4:Discrete(2)), candidate_strengths:Dict(candidate_0:Discrete(101), candidate_1:Discrete(101), candidate_2:Discrete(101), candidate_3:Discrete(101), candidate_4:Discrete(101)), counter_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11)), candidate_1:Tuple(Discrete(101), Discrete(11)), candidate_2:Tuple(Discrete(101), Discrete(11)), candidate_3:Tuple(Discrete(101), Discrete(11)), candidate_4:Tuple(Discrete(101), Discrete(11))), declined_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101)), candidate_1:Tuple(Discrete(2), Discrete(101)), candidate_2:Tuple(Discrete(2), Discrete(101)), candidate_3:Tuple(Discrete(2), Discrete(101)), candidate_4:Tuple(Discrete(2), Discrete(101))), job_applicants:Dict(candidate_0:Discrete(2), candidate_1:Discrete(2), candidate_2:Discrete(2), candidate_3:Discrete(2), candidate_4:Discrete(2)), outstanding_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11)), candidate_1:Tuple(Discrete(101), Discrete(11)), candidate_2:Tuple(Discrete(101), Discrete(11)), candidate_3:Tuple(Discrete(101), Discrete(11)), candidate_4:Tuple(Discrete(101), Discrete(11))), rejected_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101)), candidate_1:Tuple(Discrete(2), Discrete(101)), candidate_2:Tuple(Discrete(2), Discrete(101)), candidate_3:Tuple(Discrete(2), Discrete(101)), candidate_4:Tuple(Discrete(2), Discrete(101))), remaining_budget:Discrete(101))))",
        "Tuple(Discrete(5), Discrete(5), Discrete(101), Discrete(11))",
        {
          "model": {
            "custom_model": "EmployerModel",
            "custom_model_config": {}
          }
        }
      ]
    },
    "policies_to_train": [
      "candidate_policy",
      "employer_policy"
    ],
    "policy_map_cache": null,
    "policy_map_capacity": 100,
    "policy_mapping_fn": "<function policy_mapping_fn at 0x7f37da5b6680>"
  },
  "no_done_at_end": false,
  "normalize_actions": true,
  "num_consecutive_worker_failures_tolerance": 100,
  "num_cpus_for_driver": 1,
  "num_cpus_per_worker": 1,
  "num_envs_per_worker": 1,
  "num_gpus": 0,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 30,
  "num_workers": 2,
  "observation_filter": "MeanStdFilter",
  "observation_space": "Dict(action_mask:Box(0.0, 1.0, (122,), float32), observation:Dict(candidate_obs:Dict(accepted_offer:Dict(employer_0:Discrete(101), employer_1:Discrete(101), employer_2:Discrete(101), employer_3:Discrete(101), employer_4:Discrete(101)), counter_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11)), employer_1:Tuple(Discrete(101), Discrete(11)), employer_2:Tuple(Discrete(101), Discrete(11)), employer_3:Tuple(Discrete(101), Discrete(11)), employer_4:Tuple(Discrete(101), Discrete(11))), current_offers:Dict(employer_0:Tuple(Discrete(101), Discrete(11)), employer_1:Tuple(Discrete(101), Discrete(11)), employer_2:Tuple(Discrete(101), Discrete(11)), employer_3:Tuple(Discrete(101), Discrete(11)), employer_4:Tuple(Discrete(101), Discrete(11))), job_openings:Dict(employer_0:Discrete(2), employer_1:Discrete(2), employer_2:Discrete(2), employer_3:Discrete(2), employer_4:Discrete(2)), rejected_offers:Dict(employer_0:Tuple(Discrete(2), Discrete(101)), employer_1:Tuple(Discrete(2), Discrete(101)), employer_2:Tuple(Discrete(2), Discrete(101)), employer_3:Tuple(Discrete(2), Discrete(101)), employer_4:Tuple(Discrete(2), Discrete(101)))), employer_obs:Dict(accepted_offers:Dict(candidate_0:Discrete(2), candidate_1:Discrete(2), candidate_2:Discrete(2), candidate_3:Discrete(2), candidate_4:Discrete(2)), candidate_strengths:Dict(candidate_0:Discrete(101), candidate_1:Discrete(101), candidate_2:Discrete(101), candidate_3:Discrete(101), candidate_4:Discrete(101)), counter_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11)), candidate_1:Tuple(Discrete(101), Discrete(11)), candidate_2:Tuple(Discrete(101), Discrete(11)), candidate_3:Tuple(Discrete(101), Discrete(11)), candidate_4:Tuple(Discrete(101), Discrete(11))), declined_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101)), candidate_1:Tuple(Discrete(2), Discrete(101)), candidate_2:Tuple(Discrete(2), Discrete(101)), candidate_3:Tuple(Discrete(2), Discrete(101)), candidate_4:Tuple(Discrete(2), Discrete(101))), job_applicants:Dict(candidate_0:Discrete(2), candidate_1:Discrete(2), candidate_2:Discrete(2), candidate_3:Discrete(2), candidate_4:Discrete(2)), outstanding_offers:Dict(candidate_0:Tuple(Discrete(101), Discrete(11)), candidate_1:Tuple(Discrete(101), Discrete(11)), candidate_2:Tuple(Discrete(101), Discrete(11)), candidate_3:Tuple(Discrete(101), Discrete(11)), candidate_4:Tuple(Discrete(101), Discrete(11))), rejected_offers:Dict(candidate_0:Tuple(Discrete(2), Discrete(101)), candidate_1:Tuple(Discrete(2), Discrete(101)), candidate_2:Tuple(Discrete(2), Discrete(101)), candidate_3:Tuple(Discrete(2), Discrete(101)), candidate_4:Tuple(Discrete(2), Discrete(101))), remaining_budget:Discrete(101))))",
  "off_policy_estimation_methods": {},
  "ope_split_batch_by_episode": true,
  "optimizer": {},
  "output": null,
  "output_compress_columns": [
    "obs",
    "new_obs"
  ],
  "output_config": {},
  "output_max_file_size": 67108864,
  "placement_strategy": "PACK",
  "postprocess_inputs": false,
  "preprocessor_pref": "deepmind",
  "prioritized_replay": -1,
  "prioritized_replay_alpha": -1,
  "prioritized_replay_beta": -1,
  "prioritized_replay_eps": -1,
  "recreate_failed_workers": false,
  "remote_env_batch_wait_ms": 0,
  "remote_worker_envs": false,
  "render_env": false,
  "replay_batch_size": -1,
  "replay_mode": -1,
  "replay_sequence_length": null,
  "restart_failed_sub_environments": false,
  "rollout_fragment_length": 200,
  "sample_async": false,
  "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
  "sampler_perf_stats_ema_coef": null,
  "seed": null,
  "sgd_minibatch_size": 128,
  "shuffle_buffer_size": 0,
  "shuffle_sequences": true,
  "simple_optimizer": -1,
  "soft_horizon": false,
  "sync_filters_on_rollout_workers_timeout_s": 60.0,
  "synchronize_filters": true,
  "tf_session_args": {
    "allow_soft_placement": true,
    "device_count": {
      "CPU": 1
    },
    "gpu_options": {
      "allow_growth": true
    },
    "inter_op_parallelism_threads": 2,
    "intra_op_parallelism_threads": 2,
    "log_device_placement": false
  },
  "timesteps_per_iteration": -1,
  "train_batch_size": 4000,
  "use_critic": true,
  "use_gae": true,
  "validate_workers_after_construction": true,
  "vf_clip_param": 10.0,
  "vf_loss_coeff": 1.0,
  "vf_share_layers": -1
}